# main.py
# Streamlit: ì§€ì—­ë³„ ì˜ë£Œí–‰ìœ„(ì‹¬í‰ì›) Ã— ì¸êµ¬ì¦ê°(ì£¼ë¯¼ë“±ë¡) + ì‹œë„ ê²½ê³„ ì§€ë„(Choropleth)
# ì‹¤í–‰: streamlit run main.py

import os
import re
import requests
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px

st.set_page_config(page_title="ì§€ì—­ë³„ ì˜ë£Œí–‰ìœ„ Ã— ì¸êµ¬ì¦ê° ëŒ€ì‹œë³´ë“œ", layout="wide")


# -----------------------------
# CSV loader (auto-encoding)
# -----------------------------
def read_csv_auto(uploaded_file) -> pd.DataFrame:
    raw = uploaded_file.getvalue()
    for enc in ["utf-8-sig", "cp949", "euc-kr", "utf-8"]:
        try:
            return pd.read_csv(pd.io.common.BytesIO(raw), encoding=enc)
        except Exception:
            continue
    return pd.read_csv(pd.io.common.BytesIO(raw))


def read_csv_from_path(path: str) -> pd.DataFrame:
    for enc in ["utf-8-sig", "cp949", "euc-kr", "utf-8"]:
        try:
            return pd.read_csv(path, encoding=enc)
        except Exception:
            continue
    return pd.read_csv(path)


def to_numeric_safe(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s.astype(str).str.replace(",", "").str.strip(), errors="coerce")


def normalize_sido_from_pop(í–‰ì •êµ¬ì—­: str) -> str:
    if pd.isna(í–‰ì •êµ¬ì—­):
        return np.nan

    name = re.sub(r"\s*\(.*?\)\s*", "", str(í–‰ì •êµ¬ì—­)).strip()
    name = re.sub(r"\s+", " ", name)

    name = (
        name.replace("íŠ¹ë³„ì‹œ", "")
        .replace("ê´‘ì—­ì‹œ", "")
        .replace("íŠ¹ë³„ìì¹˜ì‹œ", "")
        .replace("íŠ¹ë³„ìì¹˜ë„", "")
        .replace("ìì¹˜ë„", "")
        .replace("ë„", "")
    ).strip()

    mapping = {
        "ì„œìš¸": "ì„œìš¸",
        "ë¶€ì‚°": "ë¶€ì‚°",
        "ëŒ€êµ¬": "ëŒ€êµ¬",
        "ì¸ì²œ": "ì¸ì²œ",
        "ê´‘ì£¼": "ê´‘ì£¼",
        "ëŒ€ì „": "ëŒ€ì „",
        "ìš¸ì‚°": "ìš¸ì‚°",
        "ì„¸ì¢…": "ì„¸ì¢…",
        "ê²½ê¸°": "ê²½ê¸°",
        "ê°•ì›": "ê°•ì›",
        "ì¶©ì²­ë¶": "ì¶©ë¶",
        "ì¶©ì²­ë‚¨": "ì¶©ë‚¨",
        "ì „ë¼ë¶": "ì „ë¶",
        "ì „ë¼ë‚¨": "ì „ë‚¨",
        "ê²½ìƒë¶": "ê²½ë¶",
        "ê²½ìƒë‚¨": "ê²½ë‚¨",
        "ì œì£¼": "ì œì£¼",
    }
    return mapping.get(name, name)


# -----------------------------
# GeoJSON (no file needed)
# -----------------------------
@st.cache_data(show_spinner=False)
def load_korea_sido_geojson():
    url = "https://simplemaps.com/static/svg/country/kr/admin1/kr.json"
    r = requests.get(url, timeout=30)
    r.raise_for_status()
    return r.json()


GEO_ID_BY_SIDO = {
    "ì„œìš¸": "KR11",
    "ë¶€ì‚°": "KR26",
    "ëŒ€êµ¬": "KR27",
    "ì¸ì²œ": "KR28",
    "ê´‘ì£¼": "KR29",
    "ëŒ€ì „": "KR30",
    "ìš¸ì‚°": "KR31",
    "ê²½ê¸°": "KR41",
    "ê°•ì›": "KR42",
    "ì¶©ë¶": "KR43",
    "ì¶©ë‚¨": "KR44",
    "ì „ë¶": "KR45",
    "ì „ë‚¨": "KR46",
    "ê²½ë¶": "KR47",
    "ê²½ë‚¨": "KR48",
    "ì œì£¼": "KR49",
    "ì„¸ì¢…": "KR50",
}

SIDO_CENTROIDS = {
    "ì„œìš¸": (37.5665, 126.9780),
    "ë¶€ì‚°": (35.1796, 129.0756),
    "ëŒ€êµ¬": (35.8714, 128.6014),
    "ì¸ì²œ": (37.4563, 126.7052),
    "ê´‘ì£¼": (35.1595, 126.8526),
    "ëŒ€ì „": (36.3504, 127.3845),
    "ìš¸ì‚°": (35.5384, 129.3114),
    "ì„¸ì¢…": (36.4800, 127.2890),
    "ê²½ê¸°": (37.4138, 127.5183),
    "ê°•ì›": (37.8228, 128.1555),
    "ì¶©ë¶": (36.6357, 127.4917),
    "ì¶©ë‚¨": (36.6588, 126.6728),
    "ì „ë¶": (35.7175, 127.1530),
    "ì „ë‚¨": (34.8161, 126.4629),
    "ê²½ë¶": (36.4919, 128.8889),
    "ê²½ë‚¨": (35.4606, 128.2132),
    "ì œì£¼": (33.4996, 126.5312),
}


# -----------------------------
# Auto-detect repo CSV paths
# -----------------------------
def list_repo_csv_files(base_dir="."):
    try:
        return sorted([f for f in os.listdir(base_dir) if f.lower().endswith(".csv")])
    except Exception:
        return []


def detect_default_paths(csv_files):
    # heuristic keyword matching
    hira_keys = ["ì˜ë£Œí–‰ìœ„", "ì‹¬ì‚¬í‰ê°€ì›", "ì§„ë£Œ", "ê±´ê°•ë³´í—˜", "ì‹¬í‰ì›"]
    pop_keys = ["ì£¼ë¯¼ë“±ë¡", "ì¸êµ¬ì¦ê°", "ì¸êµ¬ê¸°íƒ€í˜„í™©", "ì›”ê°„"]

    def score(name, keys):
        s = 0
        for k in keys:
            if k in name:
                s += 1
        return s

    # choose best match by score
    hira_best = max(csv_files, key=lambda x: score(x, hira_keys), default=None)
    pop_best = max(csv_files, key=lambda x: score(x, pop_keys), default=None)

    # ensure score >= 1, else None
    hira_best = hira_best if hira_best and score(hira_best, hira_keys) >= 1 else None
    pop_best = pop_best if pop_best and score(pop_best, pop_keys) >= 1 else None
    return hira_best, pop_best


# -----------------------------
# Population preprocessing
# -----------------------------
def preprocess_population(pop_raw: pd.DataFrame) -> pd.DataFrame:
    df = pop_raw.copy()

    if "í–‰ì •êµ¬ì—­" not in df.columns:
        raise ValueError("ì¸êµ¬ ë°ì´í„°ì— 'í–‰ì •êµ¬ì—­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["ì‹œë„"] = df["í–‰ì •êµ¬ì—­"].apply(normalize_sido_from_pop)

    month_prefix = None
    for c in df.columns:
        m = re.match(r"(\d{4}ë…„\d{1,2}ì›”)_", str(c))
        if m:
            month_prefix = m.group(1)
            break
    if not month_prefix:
        raise ValueError("ì¸êµ¬ ë°ì´í„°ì—ì„œ 'YYYYë…„Mì›”_' í˜•íƒœì˜ ì»¬ëŸ¼ ì ‘ë‘ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # robust column finding
    def find_col(cols, must_include):
        for c in cols:
            ok = True
            for k in must_include:
                if k not in str(c):
                    ok = False
                    break
            if ok:
                return c
        return None

    prev_col = find_col(df.columns, [month_prefix, "ì „ì›”", "ì¸êµ¬"])
    curr_col = find_col(df.columns, [month_prefix, "ë‹¹ì›”", "ì¸êµ¬"])
    diff_col = find_col(df.columns, [month_prefix, "ì¦ê°"])

    if (prev_col is None) or (curr_col is None) or (diff_col is None):
        raise ValueError(
            "ì¸êµ¬ ë°ì´í„° ì»¬ëŸ¼ ìë™ íƒì§€ ì‹¤íŒ¨ì…ë‹ˆë‹¤.\n"
            f"- íƒì§€ëœ month_prefix: {month_prefix}\n"
            f"- ì»¬ëŸ¼ ì¼ë¶€: {list(df.columns)[:25]}"
        )

    df["ì „ì›”ì¸êµ¬"] = to_numeric_safe(df[prev_col])
    df["ë‹¹ì›”ì¸êµ¬"] = to_numeric_safe(df[curr_col])
    df["ì¸êµ¬ì¦ê°"] = to_numeric_safe(df[diff_col])
    df["ì¸êµ¬ì¦ê°ë¥ (%)"] = np.where(df["ì „ì›”ì¸êµ¬"] > 0, (df["ì¸êµ¬ì¦ê°"] / df["ì „ì›”ì¸êµ¬"]) * 100, np.nan)

    ym = re.match(r"(\d{4})ë…„(\d{1,2})ì›”", month_prefix)
    df["ì¸êµ¬ê¸°ì¤€ì—°ë„"] = int(ym.group(1)) if ym else np.nan
    df["ì¸êµ¬ê¸°ì¤€ì›”"] = int(ym.group(2)) if ym else np.nan

    df = df[df["ì‹œë„"].notna()].copy()
    df = df[df["ì‹œë„"] != "ì „êµ­"].copy()

    df["lat"] = df["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[0])
    df["lon"] = df["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[1])

    return df[["ì‹œë„", "ì „ì›”ì¸êµ¬", "ë‹¹ì›”ì¸êµ¬", "ì¸êµ¬ì¦ê°", "ì¸êµ¬ì¦ê°ë¥ (%)", "ì¸êµ¬ê¸°ì¤€ì—°ë„", "ì¸êµ¬ê¸°ì¤€ì›”", "lat", "lon"]]


# -----------------------------
# HIRA preprocessing & aggregation
# -----------------------------
def preprocess_hira(hira_raw: pd.DataFrame) -> pd.DataFrame:
    required = ["ì§„ë£Œë…„ë„", "ì‹œë„", "í–‰ìœ„ì½”ë“œ", "í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]
    missing = [c for c in required if c not in hira_raw.columns]
    if missing:
        raise ValueError(f"ì‹¬í‰ì› ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    df = hira_raw.copy()
    for c in ["í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]:
        df[c] = to_numeric_safe(df[c])

    df["ì§„ë£Œë…„ë„"] = to_numeric_safe(df["ì§„ë£Œë…„ë„"]).astype("Int64")
    df["ì‹œë„"] = df["ì‹œë„"].astype(str).str.strip()
    df["í–‰ìœ„ì½”ë“œ"] = df["í–‰ìœ„ì½”ë“œ"].astype(str).str.strip()
    return df


def aggregate_hira_by_sido(hira_df: pd.DataFrame, year: int, fillna_zero: bool = True) -> pd.DataFrame:
    df = hira_df[hira_df["ì§„ë£Œë…„ë„"] == year].copy()
    if fillna_zero:
        cols = ["í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]
        df[cols] = df[cols].fillna(0)

    agg = df.groupby("ì‹œë„", as_index=False).agg(
        í™˜ììˆ˜=("í™˜ììˆ˜", "sum"),
        ëª…ì„¸ì„œê±´ìˆ˜=("ëª…ì„¸ì„œê±´ìˆ˜", "sum"),
        ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰=("ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "sum"),
        ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡=("ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡", "sum"),
        í–‰ìœ„ì½”ë“œì¢…ë¥˜ìˆ˜=("í–‰ìœ„ì½”ë“œ", "nunique"),
    )
    agg["ì§„ë£Œë…„ë„"] = year
    return agg


# -----------------------------
# UI
# -----------------------------
st.title("ğŸ“ ì§€ì—­ë³„ ì˜ë£Œí–‰ìœ„(ì‹¬í‰ì›) Ã— ì¸êµ¬ì¦ê°(ì£¼ë¯¼ë“±ë¡) ëŒ€ì‹œë³´ë“œ")

repo_csvs = list_repo_csv_files(".")
auto_hira, auto_pop = detect_default_paths(repo_csvs)

with st.sidebar:
    st.header("1) ë°ì´í„° ì†ŒìŠ¤")

    # ë””ë²„ê·¸ìš©: í˜„ì¬ í´ë” íŒŒì¼ í™•ì¸(í•„ìš”ì—†ìœ¼ë©´ ì£¼ì„ ì²˜ë¦¬)
    with st.expander("ğŸ“ í˜„ì¬ í´ë” CSV ëª©ë¡ ë³´ê¸°", expanded=False):
        st.write(repo_csvs if repo_csvs else "CSV íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ë ˆí¬ì— ì—…ë¡œë“œ ë˜ì—ˆëŠ”ì§€ í™•ì¸)")

    source_mode = st.radio(
        "CSV ë¡œë”© ë°©ì‹",
        ["ë ˆí¬ íŒŒì¼ ìë™ ë¡œë“œ(ì¶”ì²œ)", "ì—…ë¡œë“œ(file_uploader)ë¡œ ì‚¬ìš©"],
        index=0,
    )

    st.divider()
    st.header("2) ì—…ë¡œë“œ(ì„ íƒ)")
    hira_up = st.file_uploader("ì‹¬í‰ì› ì˜ë£Œí–‰ìœ„ CSV ì—…ë¡œë“œ", type=["csv"])
    pop_up = st.file_uploader("ì£¼ë¯¼ë“±ë¡ ì¸êµ¬ì¦ê° CSV ì—…ë¡œë“œ", type=["csv"])

    st.divider()
    st.header("3) ì˜µì…˜")
    fillna_zero = st.checkbox("ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì²˜ë¦¬(ê¶Œì¥)", value=True)
    top_n = st.slider("Top N (ë­í‚¹/í‘œ)", 5, 30, 15)

# Resolve paths (this "prints" defaults accurately)
if source_mode == "ë ˆí¬ íŒŒì¼ ìë™ ë¡œë“œ(ì¶”ì²œ)":
    # If user uploaded, prefer uploaded
    if hira_up is not None and pop_up is not None:
        st.sidebar.success("ì—…ë¡œë“œ íŒŒì¼ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.")
        hira_raw = read_csv_auto(hira_up)
        pop_raw = read_csv_auto(pop_up)
        DEFAULT_HIRA_PATH = "(uploaded)"
        DEFAULT_POP_PATH = "(uploaded)"
    else:
        # If not uploaded, use auto-detected repo files (or user pick)
        if not repo_csvs:
            st.error("ë ˆí¬ í´ë”ì—ì„œ CSV íŒŒì¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. main.pyì™€ ê°™ì€ ìœ„ì¹˜ì— CSVê°€ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
            st.stop()

        # Let user override if detection failed / or want explicit choice
        st.sidebar.subheader("ìë™ íƒì§€ëœ ê¸°ë³¸ íŒŒì¼")
        st.sidebar.write("DEFAULT_HIRA_PATH:", auto_hira or "íƒì§€ ì‹¤íŒ¨")
        st.sidebar.write("DEFAULT_POP_PATH:", auto_pop or "íƒì§€ ì‹¤íŒ¨")

        hira_choice = st.sidebar.selectbox(
            "ì‹¬í‰ì› CSV ì„ íƒ(ë ˆí¬ ë‚´)",
            options=repo_csvs,
            index=repo_csvs.index(auto_hira) if auto_hira in repo_csvs else 0,
        )
        pop_choice = st.sidebar.selectbox(
            "ì¸êµ¬ì¦ê° CSV ì„ íƒ(ë ˆí¬ ë‚´)",
            options=repo_csvs,
            index=repo_csvs.index(auto_pop) if auto_pop in repo_csvs else min(1, len(repo_csvs) - 1),
        )

        DEFAULT_HIRA_PATH = hira_choice
        DEFAULT_POP_PATH = pop_choice

        try:
            hira_raw = read_csv_from_path(DEFAULT_HIRA_PATH)
            pop_raw = read_csv_from_path(DEFAULT_POP_PATH)
            st.sidebar.success("ë ˆí¬ ë‚´ CSVë¥¼ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
        except Exception as e:
            st.error(f"ë ˆí¬ CSV ë¡œë”© ì˜¤ë¥˜: {e}")
            st.stop()

else:
    # upload mode
    if hira_up is None or pop_up is None:
        st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ ì‹¬í‰ì› CSVì™€ ì¸êµ¬ì¦ê° CSVë¥¼ ì—…ë¡œë“œí•˜ë©´ ëŒ€ì‹œë³´ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
        st.stop()

    hira_raw = read_csv_auto(hira_up)
    pop_raw = read_csv_auto(pop_up)
    DEFAULT_HIRA_PATH = "(uploaded)"
    DEFAULT_POP_PATH = "(uploaded)"

# Show resolved defaults in main page too
st.caption(f"ğŸ“Œ ì‚¬ìš© ì¤‘ì¸ íŒŒì¼: ì‹¬í‰ì›={DEFAULT_HIRA_PATH} / ì¸êµ¬={DEFAULT_POP_PATH}")

# Preprocess
try:
    hira = preprocess_hira(hira_raw)
    pop = preprocess_population(pop_raw)
except Exception as e:
    st.error(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    st.stop()

# Year selector
years = sorted([int(y) for y in hira["ì§„ë£Œë…„ë„"].dropna().unique()])
if not years:
    st.error("ì‹¬í‰ì› ë°ì´í„°ì—ì„œ 'ì§„ë£Œë…„ë„'ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
    st.stop()

default_year = years[-1]
left, right = st.columns([1, 2])
with left:
    year = st.selectbox("ì§„ë£Œë…„ë„ ì„ íƒ", options=years, index=years.index(default_year))
with right:
    st.caption("â€» ì¸êµ¬ ë°ì´í„°ëŠ” ì—…ë¡œë“œ/ë ˆí¬ íŒŒì¼ì˜ ì›”(ì „ì›”â†’ë‹¹ì›” ì¦ê°ë¥ )ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤.")

# Aggregate & merge
hira_sido = aggregate_hira_by_sido(hira, year=year, fillna_zero=fillna_zero)
merged = hira_sido.merge(pop, on="ì‹œë„", how="left")

# Derived metrics
merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"] = np.where(merged["ë‹¹ì›”ì¸êµ¬"] > 0, (merged["ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰"] / merged["ë‹¹ì›”ì¸êµ¬"]) * 10000, np.nan)
merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡"] = np.where(merged["ë‹¹ì›”ì¸êµ¬"] > 0, (merged["ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"] / merged["ë‹¹ì›”ì¸êµ¬"]) * 10000, np.nan)
merged["í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡"] = np.where(merged["í™˜ììˆ˜"] > 0, merged["ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"] / merged["í™˜ììˆ˜"], np.nan)

national_avg = np.nanmean(merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"])
merged["í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"] = (
    merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"] / national_avg
    if national_avg and not np.isnan(national_avg)
    else np.nan
)

merged["geo_id"] = merged["ì‹œë„"].map(GEO_ID_BY_SIDO)

# Filters
all_sidos = [s for s in merged["ì‹œë„"].dropna().unique().tolist()]
sel_sidos = st.multiselect("í‘œì‹œí•  ì‹œë„ ì„ íƒ(ë¯¸ì„ íƒ ì‹œ ì „ì²´)", options=all_sidos, default=all_sidos)
view = merged[merged["ì‹œë„"].isin(sel_sidos)].copy()

# KPI
k1, k2, k3, k4 = st.columns(4)
k1.metric("ì‹œë„ ìˆ˜", f"{view['ì‹œë„'].nunique()}ê°œ")
k2.metric("ì˜ë£Œí–‰ìœ„ ì²­êµ¬ê¸ˆì•¡ í•©ê³„", f"{view['ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡'].sum():,.0f}")
k3.metric("ì¸êµ¬ 1ë§Œëª…ë‹¹ ì´ì‚¬ìš©ëŸ‰(í‰ê· )", f"{np.nanmean(view['ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰']):,.2f}")
k4.metric("ì¸êµ¬ ì¦ê°ë¥ (í‰ê· , %)", f"{np.nanmean(view['ì¸êµ¬ì¦ê°ë¥ (%)']):,.3f}")

st.divider()

tab1, tab2, tab3 = st.tabs(["ğŸ«§ ë²„ë¸”(ì¸êµ¬ì¦ê° Ã— ì˜ë£Œì´ìš©)", "ğŸ—ºï¸ ì‹œë„ ê²½ê³„ ì§€ë„(Choropleth)", "ğŸ“‹ ë­í‚¹/í…Œì´ë¸”"])

# Tab 1: Bubble
with tab1:
    metric_choice = st.radio(
        "Yì¶• ì§€í‘œ ì„ íƒ",
        ["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡"],
        horizontal=True,
    )

    bubble = view.copy()
    bubble["ë²„ë¸”í¬ê¸°(ì¸êµ¬)"] = bubble["ë‹¹ì›”ì¸êµ¬"]
    bubble["ë¼ë²¨"] = bubble["ì‹œë„"]

    fig = px.scatter(
        bubble,
        x="ì¸êµ¬ì¦ê°ë¥ (%)",
        y=metric_choice,
        size="ë²„ë¸”í¬ê¸°(ì¸êµ¬)",
        hover_name="ë¼ë²¨",
        hover_data={
            "ë‹¹ì›”ì¸êµ¬": ":,",
            "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰": ":,",
            "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡": ":,",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰": ":.2f",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡": ":.2f",
            "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡": ":.2f",
            "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)": ":.2f",
        },
        labels={
            "ì¸êµ¬ì¦ê°ë¥ (%)": "ì¸êµ¬ ì¦ê°ë¥ (%) (ì „ì›”â†’ë‹¹ì›”)",
            metric_choice: metric_choice,
        },
        title="ì¸êµ¬ ë³€í™” vs ì˜ë£Œì´ìš©(ì¸êµ¬ë³´ì •) â€” ë²„ë¸” í¬ê¸°=ì¸êµ¬",
    )
    st.plotly_chart(fig, use_container_width=True)
    st.caption("í•´ì„ íŒ: ì¢Œìƒë‹¨(ì¸êµ¬â†“, ì˜ë£Œì´ìš©â†‘)ì€ ê³ ë ¹í™”/ë§Œì„±ì§ˆí™˜/ê³µê¸‰ êµ¬ì¡° ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•  ìˆ˜ ìˆì–´ìš”.")

# Tab 2: Choropleth
with tab2:
    st.subheader("ğŸ—ºï¸ ì‹œë„ ê²½ê³„ ì§€ë„(Choropleth)")

    map_metric = st.selectbox(
        "ì§€ë„ì—ì„œ ìƒ‰ìœ¼ë¡œ í‘œí˜„í•  ì§€í‘œ",
        ["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "ì¸êµ¬ì¦ê°ë¥ (%)", "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"],
    )

    map_df = view.dropna(subset=["geo_id"]).copy()

    # ì•ˆì „ëª¨ë“œ: ì™¸ë¶€ GeoJSON ë‹¤ìš´ë¡œë“œë¥¼ ë§‰ê³ , ì  ì§€ë„ ì‚¬ìš©
    safe_mode = st.checkbox("ì§€ë„ ì•ˆì „ëª¨ë“œ(ì™¸ë¶€ ê²½ê³„ ë‹¤ìš´ë¡œë“œ ì—†ì´ ì  ì§€ë„)", value=False)

    if safe_mode:
        fallback = map_df.copy()
        fallback["lat"] = fallback["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[0])
        fallback["lon"] = fallback["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[1])
        fallback = fallback.dropna(subset=["lat", "lon"])

        fig2 = px.scatter_mapbox(
            fallback,
            lat="lat",
            lon="lon",
            size="ë‹¹ì›”ì¸êµ¬",
            color=map_metric,
            hover_name="ì‹œë„",
            zoom=5.5,
            height=650,
        )
        fig2.update_layout(mapbox_style="open-street-map", margin=dict(l=0, r=0, t=0, b=0))
        st.plotly_chart(fig2, use_container_width=True)
    else:
        try:
            geojson = load_korea_sido_geojson()

            figm = px.choropleth(
                map_df,
                geojson=geojson,
                locations="geo_id",
                featureidkey="properties.id",
                color=map_metric,
                hover_name="ì‹œë„",
                hover_data={
                    "ë‹¹ì›”ì¸êµ¬": ":,",
                    "ì¸êµ¬ì¦ê°": ":,",
                    "ì¸êµ¬ì¦ê°ë¥ (%)": ":.3f",
                    "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰": ":,",
                    "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡": ":,",
                    "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰": ":.2f",
                    "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡": ":.2f",
                    "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)": ":.2f",
                },
                labels={map_metric: map_metric},
            )
            figm.update_geos(fitbounds="locations", visible=False)
            figm.update_layout(margin=dict(l=0, r=0, t=0, b=0))
            st.plotly_chart(figm, use_container_width=True)
            st.caption("â€» ì‹œë„ ê²½ê³„ëŠ” ì‹¤í–‰ ì‹œ ì›¹ì—ì„œ ìë™ ë¡œë“œë©ë‹ˆë‹¤(ë³„ë„ íŒŒì¼ ë¶ˆí•„ìš”).")

        except Exception as e:
            st.warning(f"ê²½ê³„ GeoJSON ë¡œë“œ ì‹¤íŒ¨ â†’ ì  ì§€ë„(fallback)ë¡œ í‘œì‹œí•©ë‹ˆë‹¤.\n- ì˜¤ë¥˜: {e}")

            fallback = map_df.copy()
            fallback["lat"] = fallback["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[0])
            fallback["lon"] = fallback["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[1])
            fallback = fallback.dropna(subset=["lat", "lon"])

            fig2 = px.scatter_mapbox(
                fallback,
                lat="lat",
                lon="lon",
                size="ë‹¹ì›”ì¸êµ¬",
                color=map_metric,
                hover_name="ì‹œë„",
                zoom=5.5,
                height=650,
            )
            fig2.update_layout(mapbox_style="open-street-map", margin=dict(l=0, r=0, t=0, b=0))
            st.plotly_chart(fig2, use_container_width=True)

    show_cols = ["ì‹œë„", "ë‹¹ì›”ì¸êµ¬", "ì¸êµ¬ì¦ê°ë¥ (%)", "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"]
    st.dataframe(
        map_df[show_cols].sort_values(map_metric, ascending=False).head(top_n),
        use_container_width=True,
    )

# Tab 3: Table / ranking
with tab3:
    rank_metric = st.selectbox(
        "ë­í‚¹ ê¸°ì¤€",
        [
            "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡",
            "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰",
            "ëª…ì„¸ì„œê±´ìˆ˜",
            "í™˜ììˆ˜",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡",
            "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡",
        ],
    )

    ranked = view.sort_values(rank_metric, ascending=False).copy()

    st.subheader(f"Top {top_n} ì‹œë„ â€” {rank_metric}")

    cols = [
        "ì‹œë„",
        "ì§„ë£Œë…„ë„",
        "ë‹¹ì›”ì¸êµ¬",
        "ì¸êµ¬ì¦ê°",
        "ì¸êµ¬ì¦ê°ë¥ (%)",
        "í™˜ììˆ˜",
        "ëª…ì„¸ì„œê±´ìˆ˜",
        "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰",
        "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡",
        "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰",
        "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡",
        "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡",
        "í–‰ìœ„ì½”ë“œì¢…ë¥˜ìˆ˜",
        "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)",
    ]
    st.dataframe(ranked[cols].head(top_n), use_container_width=True)

    csv = ranked[cols].to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ì§‘ê³„ í…Œì´ë¸” CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name=f"merged_hira_pop_{year}.csv",
        mime="text/csv",
    )

st.caption("â“˜ í™˜ììˆ˜ëŠ” í–‰ìœ„ì½”ë“œë³„ ì¤‘ë³µ ì§‘ê³„ ê°€ëŠ¥ì„±ì´ ìˆì–´, ì§€ì—­ ë¹„êµëŠ” 'ì´ì‚¬ìš©ëŸ‰/ì²­êµ¬ê¸ˆì•¡/ì¸êµ¬ë³´ì • ì§€í‘œ' ì¤‘ì‹¬ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
