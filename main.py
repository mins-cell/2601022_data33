# main.py
import re
import pandas as pd
import numpy as np
import streamlit as st
import plotly.express as px
import pydeck as pdk
import json
import requests


st.set_page_config(page_title="ì§€ì—­ë³„ ì˜ë£Œí–‰ìœ„ Ã— ì¸êµ¬ì¦ê° ëŒ€ì‹œë³´ë“œ", layout="wide")

# -----------------------------
# Utilities
# -----------------------------
def read_csv_auto(file) -> pd.DataFrame:
    """Try common Korean CSV encodings automatically."""
    # Streamlit UploadedFile supports getvalue(); read bytes into buffer via pandas
    raw = file.getvalue()
    for enc in ["utf-8-sig", "cp949", "euc-kr", "utf-8"]:
        try:
            return pd.read_csv(pd.io.common.BytesIO(raw), encoding=enc)
        except Exception:
            continue
    # last resort: let pandas guess
    return pd.read_csv(pd.io.common.BytesIO(raw))

def to_numeric_safe(s: pd.Series) -> pd.Series:
    return pd.to_numeric(s.astype(str).str.replace(",", "").str.strip(), errors="coerce")

def normalize_sido_from_pop(í–‰ì •êµ¬ì—­: str) -> str:
    """
    Convert population 'í–‰ì •êµ¬ì—­' like 'ì„œìš¸íŠ¹ë³„ì‹œ  (1100000000)' -> 'ì„œìš¸'
    and match HIRA sido labels: ì„œìš¸, ë¶€ì‚°, ... ê²½ê¸°, ê°•ì›, ì¶©ë¶, ...
    """
    if pd.isna(í–‰ì •êµ¬ì—­):
        return np.nan
    # remove code in parentheses
    name = re.sub(r"\s*\(.*?\)\s*", "", str(í–‰ì •êµ¬ì—­)).strip()
    name = re.sub(r"\s+", " ", name)

    # remove suffixes
    name = (
        name.replace("íŠ¹ë³„ì‹œ", "")
            .replace("ê´‘ì—­ì‹œ", "")
            .replace("íŠ¹ë³„ìì¹˜ì‹œ", "")
            .replace("íŠ¹ë³„ìì¹˜ë„", "")
            .replace("ìì¹˜ë„", "")
            .replace("ë„", "")
    ).strip()

    # match HIRA abbreviations
    mapping = {
        "ì„œìš¸": "ì„œìš¸",
        "ë¶€ì‚°": "ë¶€ì‚°",
        "ëŒ€êµ¬": "ëŒ€êµ¬",
        "ì¸ì²œ": "ì¸ì²œ",
        "ê´‘ì£¼": "ê´‘ì£¼",
        "ëŒ€ì „": "ëŒ€ì „",
        "ìš¸ì‚°": "ìš¸ì‚°",
        "ì„¸ì¢…": "ì„¸ì¢…",
        "ê²½ê¸°": "ê²½ê¸°",
        "ê°•ì›": "ê°•ì›",
        "ì¶©ì²­ë¶": "ì¶©ë¶",
        "ì¶©ì²­ë‚¨": "ì¶©ë‚¨",
        "ì „ë¶": "ì „ë¶",
        "ì „ë¼ë¶": "ì „ë¶",
        "ì „ë‚¨": "ì „ë‚¨",
        "ì „ë¼ë‚¨": "ì „ë‚¨",
        "ê²½ë¶": "ê²½ë¶",
        "ê²½ìƒë¶": "ê²½ë¶",
        "ê²½ë‚¨": "ê²½ë‚¨",
        "ê²½ìƒë‚¨": "ê²½ë‚¨",
        "ì œì£¼": "ì œì£¼",
    }
    return mapping.get(name, name)

# Rough centroids for a scatter map (approx.)
SIDO_CENTROIDS = {
    "ì„œìš¸": (37.5665, 126.9780),
    "ë¶€ì‚°": (35.1796, 129.0756),
    "ëŒ€êµ¬": (35.8714, 128.6014),
    "ì¸ì²œ": (37.4563, 126.7052),
    "ê´‘ì£¼": (35.1595, 126.8526),
    "ëŒ€ì „": (36.3504, 127.3845),
    "ìš¸ì‚°": (35.5384, 129.3114),
    "ì„¸ì¢…": (36.4800, 127.2890),
    "ê²½ê¸°": (37.4138, 127.5183),
    "ê°•ì›": (37.8228, 128.1555),
    "ì¶©ë¶": (36.6357, 127.4917),
    "ì¶©ë‚¨": (36.6588, 126.6728),
    "ì „ë¶": (35.7175, 127.1530),
    "ì „ë‚¨": (34.8161, 126.4629),
    "ê²½ë¶": (36.4919, 128.8889),
    "ê²½ë‚¨": (35.4606, 128.2132),
    "ì œì£¼": (33.4996, 126.5312),
}

# -----------------------------
# Load & preprocess: Population
# -----------------------------
def preprocess_population(pop_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Expected columns like:
    - í–‰ì •êµ¬ì—­
    - 2025ë…„12ì›”_ì „ì›”ì¸êµ¬ìˆ˜_ê³„
    - 2025ë…„12ì›”_ë‹¹ì›”ì¸êµ¬ìˆ˜_ê³„
    - 2025ë…„12ì›”_ì¸êµ¬ì¦ê°_ê³„
    """
    df = pop_raw.copy()

    if "í–‰ì •êµ¬ì—­" not in df.columns:
        raise ValueError("ì¸êµ¬ ë°ì´í„°ì— 'í–‰ì •êµ¬ì—­' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤.")

    df["ì‹œë„"] = df["í–‰ì •êµ¬ì—­"].apply(normalize_sido_from_pop)

    # identify month prefix: e.g., '2025ë…„12ì›”_'
    month_prefix = None
    for c in df.columns:
        m = re.match(r"(\d{4}ë…„\d{1,2}ì›”)_", str(c))
        if m:
            month_prefix = m.group(1)
            break
    if not month_prefix:
        raise ValueError("ì¸êµ¬ ë°ì´í„°ì—ì„œ 'YYYYë…„Mì›”_' í˜•íƒœì˜ ì»¬ëŸ¼ ì ‘ë‘ì–´ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

    # target columns (ê³„)
    prev_col = f"{month_prefix}_ì „ì›”ì¸êµ¬ìˆ˜_ê³„"
    curr_col = f"{month_prefix}_ë‹¹ì›”ì¸êµ¬ìˆ˜_ê³„"
    diff_col = f"{month_prefix}_ì¸êµ¬ì¦ê°_ê³„"

    missing = [c for c in [prev_col, curr_col, diff_col] if c not in df.columns]
    if missing:
        raise ValueError(f"ì¸êµ¬ ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    df["ì „ì›”ì¸êµ¬"] = to_numeric_safe(df[prev_col])
    df["ë‹¹ì›”ì¸êµ¬"] = to_numeric_safe(df[curr_col])
    df["ì¸êµ¬ì¦ê°"] = to_numeric_safe(df[diff_col])
    df["ì¸êµ¬ì¦ê°ë¥ (%)"] = np.where(df["ì „ì›”ì¸êµ¬"] > 0, (df["ì¸êµ¬ì¦ê°"] / df["ì „ì›”ì¸êµ¬"]) * 100, np.nan)

    # parse year/month
    ym = re.match(r"(\d{4})ë…„(\d{1,2})ì›”", month_prefix)
    year = int(ym.group(1)) if ym else None
    month = int(ym.group(2)) if ym else None
    df["ì¸êµ¬ê¸°ì¤€ì—°ë„"] = year
    df["ì¸êµ¬ê¸°ì¤€ì›”"] = month

    # drop ì „êµ­ row if exists (optional)
    df = df[df["ì‹œë„"].notna()].copy()
    df = df[df["ì‹œë„"] != "ì „êµ­"].copy()

    # add lat/lon
    df["lat"] = df["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[0])
    df["lon"] = df["ì‹œë„"].map(lambda x: SIDO_CENTROIDS.get(x, (np.nan, np.nan))[1])

    return df[["ì‹œë„", "ì „ì›”ì¸êµ¬", "ë‹¹ì›”ì¸êµ¬", "ì¸êµ¬ì¦ê°", "ì¸êµ¬ì¦ê°ë¥ (%)", "ì¸êµ¬ê¸°ì¤€ì—°ë„", "ì¸êµ¬ê¸°ì¤€ì›”", "lat", "lon"]]

# -----------------------------
# Load & preprocess: HIRA medical acts
# -----------------------------
def preprocess_hira(hira_raw: pd.DataFrame) -> pd.DataFrame:
    """
    Expected columns:
    ì§„ë£Œë…„ë„, ì‹œë„, í–‰ìœ„ì½”ë“œ, í™˜ììˆ˜, ëª…ì„¸ì„œê±´ìˆ˜, ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰, ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡
    """
    required = ["ì§„ë£Œë…„ë„", "ì‹œë„", "í–‰ìœ„ì½”ë“œ", "í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]
    missing = [c for c in required if c not in hira_raw.columns]
    if missing:
        raise ValueError(f"ì‹¬í‰ì› ë°ì´í„°ì— í•„ìš”í•œ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")

    df = hira_raw.copy()
    # numeric
    for c in ["í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]:
        df[c] = to_numeric_safe(df[c])
    df["ì§„ë£Œë…„ë„"] = to_numeric_safe(df["ì§„ë£Œë…„ë„"]).astype("Int64")
    df["ì‹œë„"] = df["ì‹œë„"].astype(str).str.strip()

    return df

def aggregate_hira_by_sido(hira_df: pd.DataFrame, year: int, fillna_zero: bool=True) -> pd.DataFrame:
    df = hira_df[hira_df["ì§„ë£Œë…„ë„"] == year].copy()
    if fillna_zero:
        df[["í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]] = df[["í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"]].fillna(0)

    agg = df.groupby("ì‹œë„", as_index=False).agg(
        í™˜ììˆ˜=("í™˜ììˆ˜", "sum"),
        ëª…ì„¸ì„œê±´ìˆ˜=("ëª…ì„¸ì„œê±´ìˆ˜", "sum"),
        ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰=("ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "sum"),
        ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡=("ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡", "sum"),
        í–‰ìœ„ì½”ë“œì¢…ë¥˜ìˆ˜=("í–‰ìœ„ì½”ë“œ", "nunique"),
    )
    agg["ì§„ë£Œë…„ë„"] = year
    return agg

# -----------------------------
# App UI
# -----------------------------
st.title("ğŸ“ ì§€ì—­ë³„ ì˜ë£Œí–‰ìœ„(ì‹¬í‰ì›) Ã— ì¸êµ¬ì¦ê°(ì£¼ë¯¼ë“±ë¡) ëŒ€ì‹œë³´ë“œ")

with st.sidebar:
    st.header("1) íŒŒì¼ ì—…ë¡œë“œ")
    hira_file = st.file_uploader("ì‹¬í‰ì› ì˜ë£Œí–‰ìœ„ CSV ì—…ë¡œë“œ", type=["csv"])
    pop_file = st.file_uploader("ì£¼ë¯¼ë“±ë¡ ì¸êµ¬ì¦ê° CSV ì—…ë¡œë“œ", type=["csv"])

    st.divider()
    st.header("2) ì„¤ì •")
    fillna_zero = st.checkbox("ê²°ì¸¡ì¹˜ë¥¼ 0ìœ¼ë¡œ ì²˜ë¦¬(ê¶Œì¥)", value=True)
    top_n = st.slider("Top N (í‘œ/ë­í‚¹)", 5, 30, 15)

if not hira_file or not pop_file:
    st.info("ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **ì‹¬í‰ì› CSV**ì™€ **ì¸êµ¬ì¦ê° CSV**ë¥¼ ì—…ë¡œë“œí•˜ë©´ ëŒ€ì‹œë³´ë“œê°€ ìƒì„±ë©ë‹ˆë‹¤.")
    st.stop()

# Load data
try:
    hira_raw = read_csv_auto(hira_file)
    pop_raw = read_csv_auto(pop_file)
except Exception as e:
    st.error(f"CSV ë¡œë”© ì˜¤ë¥˜: {e}")
    st.stop()

# Preprocess
try:
    hira = preprocess_hira(hira_raw)
    pop = preprocess_population(pop_raw)
except Exception as e:
    st.error(f"ì „ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
    st.stop()

# Year selector from HIRA
years = sorted([int(y) for y in hira["ì§„ë£Œë…„ë„"].dropna().unique()])
default_year = years[-1] if years else 2024

colA, colB = st.columns([1, 2])
with colA:
    year = st.selectbox("ì§„ë£Œë…„ë„ ì„ íƒ", options=years, index=years.index(default_year) if default_year in years else 0)
with colB:
    st.caption("â€» ì¸êµ¬ ë°ì´í„°ëŠ” ì—…ë¡œë“œëœ íŒŒì¼ì˜ ì›”(ì˜ˆ: 2025ë…„ 12ì›”)ì„ ê¸°ì¤€ìœ¼ë¡œ ê³„ì‚°ë©ë‹ˆë‹¤. (ì „ì›”â†”ë‹¹ì›” ì¦ê°ë¥ )")

# Aggregate HIRA by sido
hira_sido = aggregate_hira_by_sido(hira, year=year, fillna_zero=fillna_zero)

# Merge with population
merged = hira_sido.merge(pop, on="ì‹œë„", how="left")

# Per-capita metrics (per 10,000 people, using 'ë‹¹ì›”ì¸êµ¬')
merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"] = np.where(merged["ë‹¹ì›”ì¸êµ¬"] > 0, (merged["ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰"] / merged["ë‹¹ì›”ì¸êµ¬"]) * 10000, np.nan)
merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡"] = np.where(merged["ë‹¹ì›”ì¸êµ¬"] > 0, (merged["ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"] / merged["ë‹¹ì›”ì¸êµ¬"]) * 10000, np.nan)
merged["í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡"] = np.where(merged["í™˜ììˆ˜"] > 0, merged["ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡"] / merged["í™˜ììˆ˜"], np.nan)

# National average index (standardized)
national_avg = np.nanmean(merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"])
merged["í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"] = merged["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰"] / national_avg if national_avg and not np.isnan(national_avg) else np.nan

# Filters
all_sidos = [s for s in merged["ì‹œë„"].dropna().unique().tolist()]
sel_sidos = st.multiselect("í‘œì‹œí•  ì‹œë„ ì„ íƒ(ë¯¸ì„ íƒ ì‹œ ì „ì²´)", options=all_sidos, default=all_sidos)

view = merged[merged["ì‹œë„"].isin(sel_sidos)].copy()

# -----------------------------
# KPI row
# -----------------------------
k1, k2, k3, k4 = st.columns(4)
k1.metric("ì‹œë„ ìˆ˜", f"{view['ì‹œë„'].nunique()}ê°œ")
k2.metric("ì˜ë£Œí–‰ìœ„ ì²­êµ¬ê¸ˆì•¡ í•©ê³„", f"{view['ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡'].sum():,.0f}")
k3.metric("ì¸êµ¬ 1ë§Œëª…ë‹¹ ì´ì‚¬ìš©ëŸ‰(í‰ê· )", f"{np.nanmean(view['ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰']):,.2f}")
k4.metric("ì¸êµ¬ ì¦ê°ë¥ (í‰ê· , %)", f"{np.nanmean(view['ì¸êµ¬ì¦ê°ë¥ (%)']):,.3f}")

st.divider()

# -----------------------------
# Tabs
# -----------------------------
tab1, tab2, tab3 = st.tabs(["ğŸ«§ ë²„ë¸”(ì¸êµ¬ì¦ê° Ã— ì˜ë£Œì´ìš©)", "ğŸ—ºï¸ ì§€ë„(Scatter map)", "ğŸ“‹ ë­í‚¹/í…Œì´ë¸”"])

# 1) Bubble
with tab1:
    metric_choice = st.radio(
        "Yì¶• ì§€í‘œ ì„ íƒ",
        ["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡"],
        horizontal=True
    )

    bubble = view.copy()
    bubble["ë²„ë¸”í¬ê¸°(ì¸êµ¬)"] = bubble["ë‹¹ì›”ì¸êµ¬"]
    bubble["ë¼ë²¨"] = bubble["ì‹œë„"]

    fig = px.scatter(
        bubble,
        x="ì¸êµ¬ì¦ê°ë¥ (%)",
        y=metric_choice,
        size="ë²„ë¸”í¬ê¸°(ì¸êµ¬)",
        hover_name="ë¼ë²¨",
        hover_data={
            "ë‹¹ì›”ì¸êµ¬": ":,",
            "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰": ":,",
            "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡": ":,",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰": ":.2f",
            "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡": ":.2f",
            "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡": ":.2f",
        },
        labels={
            "ì¸êµ¬ì¦ê°ë¥ (%)": "ì¸êµ¬ ì¦ê°ë¥ (%) (ì „ì›”â†’ë‹¹ì›”)",
            metric_choice: metric_choice,
        },
        title="ì¸êµ¬ ë³€í™” vs ì˜ë£Œì´ìš©(ì¸êµ¬ë³´ì •) â€” ë²„ë¸” í¬ê¸°=ì¸êµ¬"
    )
    st.plotly_chart(fig, use_container_width=True)

    st.caption("í•´ì„ íŒ: ì¢Œìƒë‹¨(ì¸êµ¬â†“, ì˜ë£Œì´ìš©â†‘)ì€ ê³ ë ¹í™”/ë§Œì„±ì§ˆí™˜/ê³µê¸‰êµ¬ì¡° ë“±ì˜ ê°€ëŠ¥ì„±ì„ ì‹œì‚¬í•  ìˆ˜ ìˆì–´ìš”.")

# 2) Map (scatter)
with tab2:
    map_metric = st.selectbox(
        "ì§€ë„ì—ì„œ ìƒ‰ìœ¼ë¡œ í‘œí˜„í•  ì§€í‘œ",
        ["ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "ì¸êµ¬ì¦ê°ë¥ (%)", "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"]
    )
    map_df = view.dropna(subset=["lat", "lon"]).copy()

    # Normalize for radius
    pop_max = np.nanmax(map_df["ë‹¹ì›”ì¸êµ¬"]) if len(map_df) else 1
    map_df["radius"] = np.where(map_df["ë‹¹ì›”ì¸êµ¬"].notna(), (map_df["ë‹¹ì›”ì¸êµ¬"] / pop_max) * 80000 + 20000, 30000)

    layer = pdk.Layer(
        "ScatterplotLayer",
        data=map_df,
        get_position="[lon, lat]",
        get_radius="radius",
        get_fill_color="[200, 30, 0, 140]",  # fixed color; metric shown via tooltip + optional legend in table
        pickable=True,
    )

    tooltip = {
        "html": """
        <b>{ì‹œë„}</b><br/>
        ì¸êµ¬(ë‹¹ì›”): {ë‹¹ì›”ì¸êµ¬}<br/>
        ì¸êµ¬ì¦ê°ë¥ (%): {ì¸êµ¬ì¦ê°ë¥ (%)}
        <hr/>
        ì¸êµ¬1ë§Œëª…ë‹¹ ì´ì‚¬ìš©ëŸ‰: {ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰}<br/>
        ì¸êµ¬1ë§Œëª…ë‹¹ ì²­êµ¬ê¸ˆì•¡: {ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡}<br/>
        í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰): {í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)}
        """,
        "style": {"backgroundColor": "white", "color": "black"},
    }

    st.pydeck_chart(
        pdk.Deck(
            map_style=None,
            initial_view_state=pdk.ViewState(latitude=36.3, longitude=127.8, zoom=6),
            layers=[layer],
            tooltip=tooltip,
        ),
        use_container_width=True,
    )

    st.info(
        "ì§€ë„ëŠ” ì‹œë„ ì¤‘ì‹¬ì (ëŒ€ëµ ì¢Œí‘œ) ê¸°ë°˜ Scatter map ì…ë‹ˆë‹¤. "
        "ì •í™•í•œ í–‰ì •ê²½ê³„ ì±„ìƒ‰(choropleth)ì„ ì›í•˜ë©´ 'ì‹œë„ GeoJSON'ì„ ì¶”ê°€ë¡œ ë¶™ì—¬ì„œ í™•ì¥í•  ìˆ˜ ìˆì–´ìš”."
    )

    # Show a colored table to reflect chosen metric
    show_cols = ["ì‹œë„", "ë‹¹ì›”ì¸êµ¬", "ì¸êµ¬ì¦ê°ë¥ (%)", "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"]
    st.dataframe(
        map_df[show_cols].sort_values(map_metric, ascending=False).head(top_n),
        use_container_width=True
    )

# 3) Ranking/table
with tab3:
    rank_metric = st.selectbox(
        "ë­í‚¹ ê¸°ì¤€",
        ["ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ëª…ì„¸ì„œê±´ìˆ˜", "í™˜ììˆ˜", "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡"]
    )
    ranked = view.sort_values(rank_metric, ascending=False).copy()

    st.subheader(f"Top {top_n} ì‹œë„ â€” {rank_metric}")
    show_cols = [
        "ì‹œë„", "ì§„ë£Œë…„ë„",
        "ë‹¹ì›”ì¸êµ¬", "ì¸êµ¬ì¦ê°", "ì¸êµ¬ì¦ê°ë¥ (%)",
        "í™˜ììˆ˜", "ëª…ì„¸ì„œê±´ìˆ˜", "ì˜ë£Œí–‰ìœ„ì´ì‚¬ìš©ëŸ‰", "ì˜ë£Œí–‰ìœ„ì²­êµ¬ê¸ˆì•¡",
        "ì¸êµ¬1ë§Œëª…ë‹¹_ì´ì‚¬ìš©ëŸ‰", "ì¸êµ¬1ë§Œëª…ë‹¹_ì²­êµ¬ê¸ˆì•¡", "í™˜ìë‹¹_ì²­êµ¬ê¸ˆì•¡",
        "í–‰ìœ„ì½”ë“œì¢…ë¥˜ìˆ˜", "í‘œì¤€í™”ì§€ìˆ˜(ì´ì‚¬ìš©ëŸ‰)"
    ]
    st.dataframe(ranked[show_cols].head(top_n), use_container_width=True)

    csv = ranked[show_cols].to_csv(index=False).encode("utf-8-sig")
    st.download_button("ì§‘ê³„ í…Œì´ë¸” CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name=f"merged_hira_pop_{year}.csv", mime="text/csv")

st.caption("â“˜ í™˜ììˆ˜ëŠ” í–‰ìœ„ì½”ë“œë³„ ì¤‘ë³µ ì§‘ê³„ ê°€ëŠ¥ì„±ì´ ìˆì–´, ì§€ì—­ ë¹„êµëŠ” 'ì´ì‚¬ìš©ëŸ‰/ì²­êµ¬ê¸ˆì•¡/ì¸êµ¬ë³´ì • ì§€í‘œ' ì¤‘ì‹¬ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
